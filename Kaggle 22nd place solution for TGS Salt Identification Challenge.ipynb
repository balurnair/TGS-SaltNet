{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from networks import GCN,SEModule,Refine\n",
    "from fastai.models.senet import *\n",
    "from skimage.transform import resize\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold , KFold\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from networks import *\n",
    "from pycocotools import mask as cocomask\n",
    "from utils import *\n",
    "from lovasz_losses import lovasz_hinge\n",
    "from bam import *\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/tgs/')\n",
    "TRN_MASKS = 'trn_masks'\n",
    "TRN_IMG = 'trn_images'\n",
    "TRN_MSK = 'trn_masks'\n",
    "TST_IMG = 'tst_images'\n",
    "trn = pd.read_csv(PATH/'train.csv')\n",
    "dpth = pd.read_csv(PATH/'depths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None, alpha=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, alpha=alpha)\n",
    "    ax.set_axis_off()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDataset(Dataset):\n",
    "    def __init__(self,ds,dpth_dict):\n",
    "        self.dpth = dpth_dict\n",
    "        self.ds = ds\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        val = self.ds[i]\n",
    "        return val[0],self.dpth[self.ds.fnames[i].split('/')[1][:-4]],val[1]\n",
    "    \n",
    "class MatchedFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path):\n",
    "        self.y=y\n",
    "        assert(len(fnames)==len(y))\n",
    "        super().__init__(fnames, transform, path)\n",
    "        \n",
    "    def get_x(self, i): \n",
    "        return open_image(os.path.join(self.path, self.fnames[i]))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        return open_image(os.path.join(str(self.path), str(self.y[i])))\n",
    "\n",
    "    def get_c(self): return 0\n",
    "    \n",
    "class TestFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform,flip, path):\n",
    "        self.y=y\n",
    "        self.flip = flip\n",
    "        super().__init__(fnames, transform, path)\n",
    "        \n",
    "    def get_x(self, i): \n",
    "        im = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        return np.fliplr(im) if self.flip else im\n",
    "        \n",
    "    def get_y(self, i):\n",
    "        im = open_image(os.path.join(str(self.path), str(self.y[i])))\n",
    "        return np.fliplr(im) if self.flip else im\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = np.array([f'{TRN_IMG}/{o.name}' for o in (PATH/TRN_MASKS).iterdir()])\n",
    "y_names = np.array([f'{TRN_MASKS}/{o.name}' for o in (PATH/TRN_MASKS).iterdir()])\n",
    "tst_x = np.array([f'{TST_IMG}/{o.name}' for o in (PATH/TST_IMG).iterdir()])\n",
    "f_name = [o.split('/')[-1] for o in x_names]\n",
    "\n",
    "c = dpth.set_index('id')\n",
    "dpth_dict = c['z'].to_dict()\n",
    "\n",
    "kf = 10\n",
    "kfold = KFold(n_splits=kf, shuffle=True, random_state=42)\n",
    "\n",
    "train_folds = []\n",
    "val_folds = []\n",
    "for idxs in kfold.split(f_name):\n",
    "    train_folds.append([f_name[idx] for idx in idxs[0]])\n",
    "    val_folds.append([f_name[idx] for idx in idxs[1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rn = ResNetWithBAM()\n",
    "        fs = 16\n",
    "        self.up1 = UnetBlock(512,256,fs)\n",
    "        self.up2 = UnetBlock(fs,128,fs)\n",
    "        self.up3 = UnetBlock(fs,64,fs)\n",
    "        self.up4 = nn.ConvTranspose2d(fs, fs, 2, stride=2)\n",
    "\n",
    "        self.img_class = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                   Flatten(),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(512,256),nn.ReLU(inplace=True),nn.BatchNorm1d(256),\n",
    "                                   nn.Dropout(0.3),\n",
    "                                   nn.Linear(256,1),nn.Sigmoid()\n",
    "                                )\n",
    "        \n",
    "        self.logit = nn.Sequential(nn.Conv2d(69,69,kernel_size=3,padding=1),nn.ReLU(inplace=True),\n",
    "                           nn.Conv2d(69,1,kernel_size=1,padding=0))\n",
    "        \n",
    "        self.ds1,self.ds2,self.ds3,self.ds4,self.ds5 = [conv_block(fs,1) for _ in range(5)]\n",
    "        \n",
    "    def forward(self,img,depth):\n",
    "        e0,e1,e2,e3,e4 = self.rn(img)\n",
    "        img_sz = img.size(2)     \n",
    "        d1 = self.up1(e4, e3) \n",
    "        d2 = self.up2(d1, e2) \n",
    "        d3 = self.up3(d2, e1) \n",
    "        d4 = self.up4(d3) \n",
    "\n",
    "        #Creating hyper column features\n",
    "        hyp_column = torch.cat([create_interpolate(o,img_sz) for o in [d1,d2,d3,d4]],1)\n",
    "        \n",
    "        #Creating features for deep supervision\n",
    "        ds1,ds2,ds3,ds4 = self.ds1(d1),self.ds2(d2),self.ds3(d3),self.ds4(d4)\n",
    "        \n",
    "        ds = torch.cat([create_interpolate(o,img_sz) for o in [ds1,ds2,ds3,ds4]],1)\n",
    "        \n",
    "        #Image classifier\n",
    "        img_class = self.img_class(e4)\n",
    "        \n",
    "        img_class_up = create_interpolate(img_class.view(img_class.size(0),-1,1,1),img_sz,'nearest',None)\n",
    "        \n",
    "        #Fuse Deep supervision features\n",
    "        ds = torch.cat([hyp_column,ds,img_class_up],1)\n",
    "        \n",
    "        x = self.logit(ds)\n",
    "        \n",
    "        return x[:,0],(img_class,*[o[:,0] for o in [ds1,ds2,ds3,ds4]])\n",
    "\n",
    "\n",
    "class UnetModel():\n",
    "    def __init__(self,model,lr_cut,name='unet'):\n",
    "        self.model,self.name = model,name\n",
    "        self.lr_cut = lr_cut\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [2]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgs_model():\n",
    "    f = resnet34\n",
    "    cut,lr_cut = model_meta[f]\n",
    "    m = to_gpu(UnetWithAttention())\n",
    "    models = UnetModel(m,lr_cut)\n",
    "    learn = ConvLearner(md, models)\n",
    "    return learn\n",
    "\n",
    "def get_base(f,cut):\n",
    "    layers = cut_model(f(True), cut)\n",
    "    return nn.Sequential(*layers)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_tensor_size(targ,sz):\n",
    "    if targ.size(1) == sz:\n",
    "        return targ\n",
    "    targ_np = np.array([cv2.resize(o,dsize=(sz,sz)) for o in to_np(targ)])\n",
    "    return torch.tensor(targ_np,dtype=torch.float32,device=torch.device(\"cuda\"))\n",
    "\n",
    "def multi_lovasz_loss(logits,target):\n",
    "    logit,cl_logit,ds1,ds2,ds3,ds4 = (logits[0],*logits[1][0]) if isinstance(logits[1],list) else (logits[0],*logits[1])\n",
    "\n",
    "    cl_targets = (Flatten()(target).sum(1) != 0).type(torch.cuda.FloatTensor).view(cl_logit.size(0),-1)\n",
    "    non_empty_imgs = cl_targets.view(cl_logit.size(0),1,1)\n",
    "    cl = F.binary_cross_entropy(cl_logit,cl_targets)\n",
    "    rf_loss = lovasz_hinge(logit,target)\n",
    "    \n",
    "    #Handling deep supervised features\n",
    "    for o in [ds1,ds2,ds3,ds4]:\n",
    "        targ_rs = change_tensor_size(target,o.size(1))\n",
    "        o = o * non_empty_imgs\n",
    "        rf_loss += lovasz_hinge(o,targ_rs)\n",
    "        \n",
    "    return 0.05*cl+ rf_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = 'submission_model'\n",
    "bst_acc=[]\n",
    "use_clr_min=20\n",
    "use_clr_div=10\n",
    "aug_tfms = [\n",
    "            RandomRotate(4, tfm_y=TfmType.CLASS),\n",
    "            RandomFlip(tfm_y=TfmType.CLASS),\n",
    "            RandomLighting(0.1, 0, tfm_y=TfmType.CLASS),\n",
    "            RandomBlur([3,5,7]),\n",
    "            RandomZoom(0.1,tfm_y=TfmType.CLASS)\n",
    "           ]\n",
    "\n",
    "szs = [(224,16)]\n",
    "for sz,bs in szs:\n",
    "    print([sz,bs])\n",
    "    for i in range(kf) :\n",
    "        print(f'fold_id{i}')\n",
    "        \n",
    "        trn_x = np.array([f'trn_images/{o}' for o in train_folds[i]])\n",
    "        trn_y = np.array([f'trn_masks/{o}' for o in train_folds[i]])\n",
    "        val_x = [f'trn_images/{o}' for o in val_folds[i]]\n",
    "        val_y = [f'trn_masks/{o}' for o in val_folds[i]]\n",
    "        \n",
    "        tfms = tfms_from_model(resnet34, sz=sz, pad=0,crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n",
    "        datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), (val_x,val_y), tfms,test=tst_x,path=PATH)\n",
    "        md = ImageData(PATH, datasets, bs, num_workers=16, classes=None)\n",
    "        denorm = md.trn_ds.denorm\n",
    "        md.trn_dl.dataset = DepthDataset(md.trn_ds,dpth_dict)\n",
    "        md.val_dl.dataset = DepthDataset(md.val_ds,dpth_dict)\n",
    "        md.test_dl.dataset = DepthDataset(md.test_ds,dpth_dict)\n",
    "        learn = get_tgs_model() \n",
    "        learn.metrics=[my_eval]\n",
    "        pa = f'{kf}_fold_{model}_{i}'\n",
    "        print(pa)\n",
    "        learn.unfreeze()        \n",
    "        learn.crit = multi_lovasz_loss     \n",
    "        \n",
    "        learn.fit(1e-2,n_cycle=1,wds=0.0001,cycle_len=100,use_clr=(10,8),best_save_name=pa)\n",
    "        \n",
    "        learn.load(pa)\n",
    "        #Calcuating mean iou score\n",
    "        v_targ = md.val_ds.ds[:][1]\n",
    "        v_preds = np.zeros((len(v_targ),sz,sz))     \n",
    "        v_pred = learn.predict()\n",
    "        v_pred = to_np(torch.sigmoid(torch.from_numpy(v_pred)))\n",
    "        p = ((v_pred)>0.5).astype(np.uint8)\n",
    "        bst_acc.append(intersection_over_union_thresholds(v_targ,p))\n",
    "        print(bst_acc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission - TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bba17f719a422ba82f0b91235f6d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_fold_resnet_ds_0ft\n",
      "10_fold_resnet_ds_1ft\n",
      "10_fold_resnet_ds_2ft\n",
      "10_fold_resnet_ds_3ft\n",
      "10_fold_resnet_ds_4ft\n",
      "10_fold_resnet_ds_5ft\n",
      "10_fold_resnet_ds_6ft\n",
      "10_fold_resnet_ds_7ft\n",
      "10_fold_resnet_ds_8ft\n",
      "10_fold_resnet_ds_9ft\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f4a17057bc4b47911111b2c8c3b941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_fold_resnet_ds_0ft\n",
      "10_fold_resnet_ds_1ft\n",
      "10_fold_resnet_ds_2ft\n",
      "10_fold_resnet_ds_3ft\n",
      "10_fold_resnet_ds_4ft\n",
      "10_fold_resnet_ds_5ft\n",
      "10_fold_resnet_ds_6ft\n",
      "10_fold_resnet_ds_7ft\n",
      "10_fold_resnet_ds_8ft\n",
      "10_fold_resnet_ds_9ft\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros(shape = (18000,sz,sz))\n",
    "for o in [True,False]:\n",
    "    md.test_dl.dataset = TestFilesDataset(tst_x,tst_x,tfms[1],flip=o,path=PATH)\n",
    "    md.test_dl.dataset = DepthDataset(md.test_dl.dataset,dpth_dict)\n",
    "    \n",
    "    for i in tqdm_notebook(range(kf)):\n",
    "        pa = f'{kf}_fold_{model}_{i}'\n",
    "        print(pa)\n",
    "        learn.load(pa)\n",
    "        pred = learn.predict(is_test=True)\n",
    "        pred = to_np(torch.sigmoid(torch.from_numpy(pred)))    \n",
    "        for im_idx,im in enumerate(pred):\n",
    "                preds[im_idx] += np.fliplr(im) if o else im\n",
    "        del pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0c9b6fc978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Quick look on if the submission masks looks good.\n",
    "plt.imshow(((preds[16]/kf*2)>0.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [cv2.resize(o/kf*2,dsize=(101,101)) for o in preds]\n",
    "p = [(o>0.5).astype(np.uint8) for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ab4f5f0dd945eca5ff83514beeec81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dict = {id_[11:-4]:RLenc(p[i]) for i,id_ in tqdm_notebook(enumerate(tst_x))}\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('simple_k_fold_flipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
